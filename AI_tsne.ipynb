## T-SNE plots for representing the embedding space
##### This notebook generates dense vector embeddings for academic papers using the SPECTER2 model. The embeddings capture semantic similarity between papers based on their titles and abstracts, enabling downstream tasks and analysis.

##### This notebook outlines the code for visualizing the dense vector embeddings for academic papers generated using the SPECTER2 model. The embeddings capture semantic similarity between papers based on their titles and abstracts, enabling downstream tasks and analysis. We include the t-sne plots for the top 5 most cited topics in 10% of each of the domains, i.e., AI, physics and psychology

**Model**: SPECTER2 - A transformer-based model from Allen AI, specifically trained on scientific documents for document-level representation learning.

**Input:**

- S2_papers_cleaned.db - Cleaned Semantic Scholar papers with titles and abstracts (from clean_and_merge_dbs.ipynb) or downloadable from Hugging Face Hub: lalit3c/S2_CS_PHY_PYSCH_papers
- all embedding files, denoted as embeddings_< number >.db - downloadable from Hugging Face Hub: lalit3c/S2_CS_PHY_PYSCH_papers/embeddings

**Output**:
plots for top 5 most cited topics in AI, physics and psychology
#### 1. Set up the environment and import the required packages
#download the packages

import pandas as pd
import duckdb
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from plotly import colors
import openTSNE
#### 2. Connect to the S2_papers_cleaned.db database and the respective embedding files
# connect to the database

dbfile = 'S2_papers_cleaned.db'
# Create a SQL connection to our SQLite database

con = duckdb.connect(dbfile)
df_papers = con.execute("SELECT * FROM papers_with_abstracts").fetchdf()
print("Shape for the database:", df_papers.shape)
# Create a SQL connection to the embedding files 

dbfile = 'data/embeddings/embeddings_1.db'
db_file_2 = 'data/embeddings/embeddings_2.db'
db_file_3 = 'data/embeddings/embeddings_3.db'



con = duckdb.connect(dbfile)
df = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

con = duckdb.connect(db_file_2)
df_2 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()


con = duckdb.connect(db_file_3)
df_3 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_4 = 'data/embeddings/embeddings_4.db'
con = duckdb.connect(db_file_4)
df_4 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()
db_file_5 = 'data/embeddings/embeddings_5.db'
con = duckdb.connect(db_file_5)
df_5 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

# db_file_6 = 'data/embeddings/embeddings_6.db'
# con = duckdb.connect(db_file_6)
# df_6 = con.execute("SELECT * FROM embeddings").fetchdf()
# con.close()

db_file_7 = 'data/embeddings/embeddings_7.db'
con = duckdb.connect(db_file_7)
df_7 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_8 = 'data/embeddings/embeddings_8.db'
con = duckdb.connect(db_file_8)
df_8 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_9 = 'data/embeddings/embeddings_9.db'
con = duckdb.connect(db_file_9)
df_9 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_10 = 'data/embeddings/embeddings_10.db'
con = duckdb.connect(db_file_10)
df_10 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_11 = 'data/embeddings/embeddings_11.db'
con = duckdb.connect(db_file_11)
df_11 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_12 = 'data/embeddings/embeddings_12.db'
con = duckdb.connect(db_file_12)
df_12 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_13 = 'data/embeddings/embeddings_13.db'
con = duckdb.connect(db_file_13)
df_13 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_14 = 'data/embeddings/embeddings_14.db'
con = duckdb.connect(db_file_14)
df_14 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_15 = 'data/embeddings/embeddings_15.db'
con = duckdb.connect(db_file_15)
df_15 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_16 = 'data/embeddings/embeddings_16.db'
con = duckdb.connect(db_file_16)
df_16 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_17 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_17)
df_17 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_18 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_18)
df_18 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_19 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_19)
df_19 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_20 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_20)
df_20 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_21 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_21)
df_21 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_22 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_22)
df_22 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_23 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_23)
df_23 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_24 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_24)
df_24 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_25 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_25)
df_25 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_26 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_26)
df_26 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_27 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_27)
df_27 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_28 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_28)
df_28 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_29 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_29)
df_29 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()

db_file_30 = 'data/embeddings/embeddings_17.db'
con = duckdb.connect(db_file_30)
df_30 = con.execute("SELECT * FROM embeddings").fetchdf()
con.close()
##### 3. Separate out papers from the database, and merge with embeddings
# seperate out papers from the database according to the field 

is_ai = df_papers[df_papers['is_ai'] == True]
is_psych = df_papers[df_papers['is_psych'] == True]
is_physics = df_papers[df_papers['is_physics'] == True]
# arrange in descending order of citation count

is_ai = is_ai.sort_values("citation_count", ascending = False).drop(columns = ['is_psych', "is_physics"])
is_psych = is_psych.sort_values("citation_count", ascending = False).drop(columns = ['is_ai', 'is_physics'])
is_physics = is_physics.sort_values("citation_count", ascending = False).drop(columns = ['is_ai', 'is_psych'])
# extract 10% of the top cited papers

is_ai = is_ai.head(int(len(is_ai)*0.1))
is_ai.shape
is_ai = is_ai.sort_values("citation_count", ascending = False)
is_ai.head()
# group by the topics

top_ai = is_ai.groupby('primary_topic').sum()

top_ai = top_ai.sort_values("citation_count", ascending = False)
top_ai = top_ai.head()
top_ai.shape
top_ai
top_topics = list(top_ai.index)
# filter out papers that are within these topics only from the top 10% of highly cited papers

top_papers = is_ai.loc[is_ai['primary_topic'].isin(top_topics)]
top_papers.shape
#### 4. Merge the embeddings with the abstracts
# concatenate the embedding dataframes row-wise (just to bring them together)

df_all = pd.concat([df, df_2, df_3, df_4, df_5, df_7, df_8, df_9, df_10, df_11, df_12, df_13, df_14,
                df_15, df_16, df_17, df_18, df_19, df_20, df_21, df_22, df_23,
               df_24, df_25, df_26, df_27, df_28, df_29, df_30], axis = 0)
df_all.shape
# merge the embeddings and the paper details based on corpusID to get the titles and other details

merged_df = df_all.merge(top_papers, on='corpusid', how="inner")
merged_df.shape
merged_df.head()
# turn the embeddings into an array of (n_smaples, n_features)

k = []
for i in range(len(merged_df['embedding'])):
  k.append(np.array(merged_df['embedding'][i]))
k = np.array(k)
k.shape
# fit the TSNE plot and display

tsne = openTSNE.TSNE(
    perplexity=30,metric="euclidean", n_jobs=-1, random_state=42, verbose = 1
)

emb = tsne.fit(k)
labels = merged_df['primary_topic']
labels
df = merged_df.assign(label=labels_clean)

# ensure datetime
df["date"] = pd.to_datetime(df["publication_date"], errors="coerce")

# numeric time (seconds since epoch)
time_num = df["date"].astype("int64") / 1e9

t_min, t_max = time_num.min(), time_num.max()

# normalize to [0, 1]
t_norm = (time_num - t_min) / (t_max - t_min)

# older → larger
marker_size = 4 + 10 * (1 - t_norm)

# older → fainter
marker_opacity = 0.9 - 0.6 * (1 - t_norm)

import numpy as np
import pandas as pd
import plotly.graph_objects as go

labels_clean = (
    pd.Series(labels)
    .astype(str)
    .str.strip()
    .str.lower()
)

df = merged_df.assign(label=labels_clean)

# parse date column
df["date"] = pd.to_datetime(df["publication_date"], errors="coerce")

# normalize time
time_num = df["date"].astype("int64") / 1e9
t_min, t_max = time_num.min(), time_num.max()
t_norm = (time_num - t_min) / (t_max - t_min)

# older → larger & fainter
sizes = 6 + 14 * (1 - t_norm)
opacities = 0.85 - 0.55 * (1 - t_norm)

fig_tsne = go.Figure()

for lab, group in df.groupby("label"):
    idx = group.index

    fig_tsne.add_trace(
        go.Scatter(
            x=emb[idx, 0],
            y=emb[idx, 1],
            mode="markers",
            name=lab,  # legend entry
            marker=dict(
                size=sizes[idx],
                opacity=opacities[idx],
            ),
            text=group["title"],
            customdata=group["date"],
            hovertemplate=(
                "<b>%{text}</b><br>"
                "t-SNE1: %{x:.2f}<br>"
                "t-SNE2: %{y:.2f}<br>"
                "year: %{customdata|%Y}<br>"
                f"topic: {lab}"
                "<extra></extra>"
            ),
        )
    )

fig_tsne.update_layout(
    autosize=False,
    width=1000,
    height=600,
    title="t-SNE: Top 5 most cited topics in AI in the embedding space.<br> <sup> (Marker size decreases with increasing year of publication) </sup>",
    xaxis_title="t-SNE1",
    yaxis_title="t-SNE2",
    legend_title="Topic",
)


